---
layout : post
title : "O architektuře, část první: Data a cache"
---

První série článků, která se tu objeví, bude obsahovat postřehy o tom, jaká omezení jsou kladená na herní engine a jejich dopad na architekturu enginu a použité návrhové vzory. Asi nejdůležitějším takovým omezením je rychlost -- jestliže je cílová obnovovací frekvence 30 nebo 60 Hz, dává to velice omezený rozpočet 33, resp. 17 ms na jeden snímek, tj. na jeden "tik" hry. Jak dosáhneme toho, aby počítačový program pracoval rychle? Jeden z významných průkopníků informatiky, Niklaus Wirth, napsal knihu s názvem ["Algoritmy + datové strukury = programy"](https://en.wikipedia.org/wiki/Algorithms_%2B_Data_Structures_%3D_Programs), takže zkusíme začít právě u datových struktur.

<!--more-->

Základním typem datové struktury jsou kontejnery -- struktury obsahující množství objektů stejného typu, např. seznam všech objektů k vykreslení. Existuje mnoho typů kontejnerů, které se liší způsobem skladování svých dat, způsobem přístupu k datům a složitostí základních operací (vkládání a odstraňování prvků, procházení přes všechny prvky). Nechci tady dělat kompletní přehled, to by bylo na jiný článek; chci se soustředit na dva základní exempláře, na kterých ukážu poměrně důležitý jev.

<aside>Složitostí se (ve stručnosti) rozumí závislost počtu kroků (instrukcí pro procesor) nutných k vykonání operace na parametrech kontejneru (zpravidla na počtu prvků v něm obsažených). Uvádí se pomocí <a href="https://en.wikipedia.org/wiki/Big_O_notation">velkého O</a> -- složitost O(N) tedy znamená, že pokud kontejner zvětšíme stokrát, daná operace potrvá cca 100x tak dlouho. U O(N<sup>2</sup>) operací by stejné zvětšení vedlo k 10000x prodloužení, zatímco u O(log<sub>10</sub> N) operací by vedlo pouze k 3x prodloužení. Pokud by daná operace trvala stejně dlouho nezávisle na tom, kolik prvků kontejner obsahuje, pak její složitost označíme jako O(1).</aside>

Nejjednodušším příkladem kontejneru je pole, což je prostě jen blok paměti, ve kterém jsou prvky umístěné postupně za sebe. Přístup do pole je O(1), nezávisle na tom, ke kterému prvku přistupujeme, protože víme, že i-tý prvek je umístěn _i * velikost prvku_ bajtů od začátku pole. Vkládání a odstraňování prvku je složitější, protože abychom mohli prvek vložit, je potřeba pro něj udělat místo, což znamená všechny následující prvky posunout dopředu. Stejně tak je po odstranění prvku potřeba všechny následující prvky zas posunout zpět. Nejhorší takový případ je vkládání či odstraňování ze začátku pole, kde je potřeba posunout všech N prvků, a proto to považujeme za operaci se složitostí O(N).

<div class="image-container"><img src="{{ site.baseurl }}/assets/images/pole.png" /></div>

Spojový seznam je pokusem o zjednodušení vkládání a odstraňování prvků. Každý prvek spojového seznamu má svůj vlastní blok paměti, který kromě skladovaného objektu obsahuje ještě ukazatel na předchozí a následující prvek. Samotný objekt seznamu pak obsahuje jen ukazatel na první a poslední prvek v poli. Vložení nového prvku mezi dva stávající zahrnuje pouhé přesměrování jejich ukazatelů, a následovné odstranění taktéž. Jde tedy o operaci se složitostí O(1). Na druhou stranu přístup do seznamu vyžaduje sledovat ukazatele od prvního prvku až do hledaného prvku. V nehorším případě je potřeba takto projít celý seznam N prvků, takže jde o operaci se složitostí O(N).

<div class="image-container"><img src="{{ site.baseurl }}/assets/images/seznam.png" /></div>

Každý typ kontejneru má tedy své výhody a nevýhody, a zdá se, že o použití seznamu nebo pole rozhoduje jen to, jestli častěji budeme do kontejneru vkládat nové prvky, nebo jestli častěji budeme přistupovat doprostřed kontejneru. V každém případě ale budeme často vyžadovat, abychom mohli postupně projít celý kontejner od začátku až do konce. Na papíře se zdá, že tady žádný z kontejnerů není zvýhodněný -- ať už je kontejner sebechytřeji vymyšlený, pokud chceme opravdu projít každý z jeho N prvků, nelze to udělat v méně než N krocích.

Udělal jsem tedy experiment. Napsal jsem program, který vytvoří pole a seznam o jednom miliónu objektů o velikosti 8 bajtů, obě je postupně projde a změří, jak dlouho to trvalo. Výsledky byly zajímavé: projít seznam o miliónu prvků trvalo __12 ms__, zatímco projít pole trvalo __4 ms__, tedy třikrát méně. Ještě zajímavější ale je, že když jsem zmenšil velikost objektů z 8 bajtů na 1, projít seznam trvalo pořád stejně, ale projít pole najednou trvalo jen __0,3 ms__, tedy ~12x méně než pole 8-bajtových prvků a 40x méně než seznam stejné velikosti! Jak je to možné?

Jak napovídá název článku, odpovědí na tuto otázku je cache, tedy vyrovnávací paměť procesoru. Ukazuje se totiž, že přístupová rychlost hlavní paměti (RAM) [zaostává za taktovací frekvencí procesorů](http://www.eecs.berkeley.edu/~rcs/research/interactive_latency.html). Procesor v mém počítači má frekvenci 3 Ghz, takže jeden jeho cyklus trvá něco kolem 0,3 ns; pokud musí čekat 100 ns na data z RAM, znamená to ztrátu asi 300 cyklů za každý přístup. Proto je přímo na procesoru malý blok vyrovnávací paměti, který je mnohem rychlejší, ale z technických důvodů je velmi malý. Tento blok je rozdělený na řádky (obvykle o 64 bajtech). Při každém přístupu do RAM procesor zkontroluje, jestli hledaná data nejsou náhodou už v cache. Pokud ne, je potřeba data načíst z RAM; při tom se načte rovnou celý řádek a umístí se do cache. Pokud data v cache už jsou, přístup k nim je bleskový; u L1 cache je to kolem jednoho cyklu, u L2 cache (která je pomalejší, ale větší) je to méně než deset cyklů.

Procházení souvislého pole je tedy situace, kdy nám cache pomáhá. Přístup na první prvek vyžaduje načtení z RAM. Při tom se ale načte celý 64-bajtový blok -- a tedy prvních osm 8-bajtových objektů -- do cache. Do RAM je tedy potřeba přistoupit jen každých osm prvků. V případě jednobajtových objektů je to dokonce jen jednou za 64 objektů, a proto je tento případ ještě rychlejší. Oproti tomu spojový seznam je nesouvislý -- každý prvek je alokovaný zvlášť a může se nacházet na jiném místě v paměti, takže je velmi malá pravděpodobnost, že se následující prvek bude nacházet v cache.

Takže abych se vrátil k původní otázce, jak dosáhnout větších rychlostí -- je potřeba spolupracovat s hardwarem, zde konkrétně s cache. Je potřeba data, ke kterým je přistupováno zároveň, umístit co nejblíž k sobě, aby mohly do cache být načteny současně. Pokud máme data v kontejnerech, a čekáme, že přes ně budeme často procházet, pak je potřeba je umístit do souvislého bloku a ideálně k nim přistupovat postupně. [Algoritmická složitost není vše](https://www.youtube.com/watch?v=fHNmRkzxHWs) -- jak pole, tak spojový seznam mají složitost průchodu O(N), ale jeden z těchto kontejnerů je 3-40x rychlejší než ten druhý. A jak si ukážeme v příštím článku, je potřeba trochu jít proti některým hluboko zakořeněným principům moderního programování.